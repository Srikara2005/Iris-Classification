# -*- coding: utf-8 -*-
"""Iris classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yXM9ee4Erwdfvll6LyOklbaye9pGLaW9

Import Libraries
You'll need scikit-learn (for the dataset and model) and pandas or seaborn (for visualization).
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

"""Load and Explore the Data
Scikit-learn has the Iris dataset built-in. It's helpful to load it into a Pandas DataFrame to easily see it.**bold text**
"""

# Load the dataset
iris = load_iris()
X = iris.data  # The features
y = iris.target  # The labels (0, 1, 2)

# Convert to a Pandas DataFrame for easier handling
df = pd.DataFrame(X, columns=iris.feature_names)
df['species'] = y

"""A crucial step is exploratory data analysis (EDA). A pairplot from the Seaborn library is perfect for this. It shows you scatter plots for every feature pair, helping you see which features are good for separating the classes."""

# Visualize the relationships between features
sns.pairplot(df, hue='species', palette='bright')
plt.show()

"""From the above pair plot, you'll notice that the Setosa species (class 0) is very easy to separate from the other two. Versicolor and Virginica have some overlap, which is the main challenge for the model.

You must split your data into a training set (for the model to learn from) and a testing set (to see how well it performs on unseen data). A common split is 80% for training and 20% for testing.
"""

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)

"""Choose and Train a Model
For this project, K-Nearest Neighbors (KNN) is an excellent and easy-to-understand choice. It classifies a new flower by looking at the "K" (a number you choose, e.g., 3) "closest" flowers from the training data.
"""

# Initialize the model (using 3 neighbors)
knn = KNeighborsClassifier(n_neighbors=3)
# Train the model on the training data
knn.fit(X_train, y_train)

"""Evaluate the Model
Now, use the test set (which the model has never seen) to make predictions and see how accurate they are.
"""

# Make predictions on the test data
y_pred = knn.predict(X_test)
# Check the accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
# Get a detailed report
print(classification_report(y_test, y_pred, target_names=iris.target_names))

"""Test Cases"""

# New flower: [SepalL, SepalW, PetalL, PetalW]
new_flower = [[5.1, 3.5, 1.4, 0.2]]  # This is a known Setosa

prediction = knn.predict(new_flower)
predicted_species = iris.target_names[prediction[0]]

print(f"The new flower is predicted to be: {predicted_species}")

# New flower: [SepalL, SepalW, PetalL, PetalW]
new_flower = [[6.8, 3.1, 5.9, 2.2]]  # This is a known Setosa

prediction = knn.predict(new_flower)
predicted_species = iris.target_names[prediction[0]]

print(f"The new flower is predicted to be: {predicted_species}")

# New flower: [SepalL, SepalW, PetalL, PetalW]
new_flower = [[6.0, 2.8, 4.5, 1.5]]  # This is a known Setosa

prediction = knn.predict(new_flower)
predicted_species = iris.target_names[prediction[0]]

print(f"The new flower is predicted to be: {predicted_species}")

